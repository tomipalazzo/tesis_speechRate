{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "0zxKOeyTROc2"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'autoreload' was not found in history, as a file, url, nor in the user namespace.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3877\u001b[0m, in \u001b[0;36mInteractiveShell.find_user_code\u001b[0;34m(self, target, raw, py_only, skip_encoding_cookie, search_ns)\u001b[0m\n\u001b[1;32m   3876\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:                                              \u001b[38;5;66;03m# User namespace\u001b[39;00m\n\u001b[0;32m-> 3877\u001b[0m     codeobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3878\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'autoreload' is not defined",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mload\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mautoreload\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2456\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2454\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2455\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2456\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2458\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2459\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2460\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/magics/code.py:359\u001b[0m, in \u001b[0;36mCodeMagics.load\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m    357\u001b[0m opts,args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_options(arg_s,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myns:r:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    358\u001b[0m search_ns \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m opts\n\u001b[0;32m--> 359\u001b[0m contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_user_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_ns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m opts:\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3879\u001b[0m, in \u001b[0;36mInteractiveShell.find_user_code\u001b[0;34m(self, target, raw, py_only, skip_encoding_cookie, search_ns)\u001b[0m\n\u001b[1;32m   3877\u001b[0m     codeobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns)\n\u001b[1;32m   3878\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3879\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m was not found in history, as a file, url, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3880\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnor in the user namespace.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m%\u001b[39m target) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   3882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(codeobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   3883\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codeobj\n",
      "\u001b[0;31mValueError\u001b[0m: 'autoreload' was not found in history, as a file, url, nor in the user namespace."
     ]
    }
   ],
   "source": [
    "%load autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DIROcsj7Rv4g",
    "outputId": "290c10ae-5ee4-4b9f-86de-8de075c80a76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%auoreload` not found.\n"
     ]
    }
   ],
   "source": [
    "%auoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "GmHNb4OxRVD8"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from itertools import groupby\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from charsiu.src.Charsiu import Wav2Vec2ForFrameClassification, CharsiuPreprocessor_en, charsiu_forced_aligner, charsiu_chain_attention_aligner, charsiu_chain_forced_aligner, charsiu_predictive_aligner\n",
    "from charsiu.src.utils import seq2duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "q7paWfYdROc5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomi/.local/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for timit_asr contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/timit_asr\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# download timit\n",
    "timit = load_dataset('timit_asr', data_dir='/home/tomi/Documents/tesis_speechRate/timit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "psXcfdsd48NJ",
    "outputId": "8b13c545-1e59-4e4e-cb4e-d3b021a88e3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text transcription:Don't ask me to carry an oily rag like that.\n",
      "Audio path: /home/tomi/Documents/tesis_speechRate/timit/data/TRAIN/DR1/FCJF0/SA2.WAV\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "sample = timit['train'][1]\n",
    "text = sample['text']\n",
    "audio_path = sample['file']\n",
    "print('Text transcription:%s'%(text))\n",
    "print('Audio path: %s'%audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUye9Hgpzpxb"
   },
   "source": [
    "Phone recognizer + Neural Forced Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "yHW92QgDROc4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at charsiu/en_w2v2_fs_10ms were not used when initializing Wav2Vec2ForAttentionAlignment: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForAttentionAlignment from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForAttentionAlignment from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForAttentionAlignment were not initialized from the model checkpoint at charsiu/en_w2v2_fs_10ms and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at charsiu/en_w2v2_ctc_libris_and_cv were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at charsiu/en_w2v2_ctc_libris_and_cv and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Wav2Vec2ForCTC(\n",
       "  (wav2vec2): Wav2Vec2Model(\n",
       "    (feature_extractor): Wav2Vec2FeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Wav2Vec2GroupNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): Wav2Vec2FeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): Wav2Vec2Encoder(\n",
       "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "        (conv): ParametrizedConv1d(\n",
       "          768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (padding): Wav2Vec2SamePadLayer()\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (lm_head): Linear(in_features=768, out_features=42, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "charsiu = charsiu_chain_attention_aligner(aligner='charsiu/en_w2v2_fs_10ms',recognizer='charsiu/en_w2v2_ctc_libris_and_cv')\n",
    "charsiu.recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gJkF2z91ROc5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomi/Documents/tesis_speechRate/charsiu/src/Charsiu.py:372: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  audio = torch.tensor(audio).float().unsqueeze(0).to(self.device)\n"
     ]
    }
   ],
   "source": [
    "alignment = charsiu.align(audio=audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "charsiu.recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gLE1r9LQ5CYq",
    "outputId": "cdd35c8f-620b-4d04-d51e-bf37d9ebcf21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 0.1, '[SIL]'), (0.1, 0.13, '[UNK]'), (0.13, 0.17, 'S'), (0.17, 0.19, '[UNK]'), (0.19, 0.22, 'L'), (0.22, 0.26, '[UNK]'), (0.26, 0.28, 'D'), (0.28, 0.32, 'T'), (0.32, 0.38, '[UNK]'), (0.38, 0.39, 'W'), (0.39, 0.43, '[UNK]'), (0.43, 0.48, 'S'), (0.48, 0.52, 'K'), (0.52, 0.55, 'M'), (0.55, 0.59, '[UNK]'), (0.59, 0.6, 'Y'), (0.6, 0.63, 'T'), (0.63, 0.64, '[UNK]'), (0.64, 0.68, 'W'), (0.68, 0.75, 'K'), (0.75, 0.87, '[UNK]'), (0.87, 0.91, 'R'), (0.91, 0.94, '[UNK]'), (0.94, 0.96, 'Y'), (0.96, 0.99, '[UNK]'), (0.99, 1.04, 'N'), (1.04, 1.05, '[UNK]'), (1.05, 1.13, 'Y'), (1.13, 1.18, 'W'), (1.18, 1.19, '[UNK]'), (1.19, 1.2, 'W'), (1.2, 1.24, '[UNK]'), (1.24, 1.32, 'L'), (1.32, 1.41, 'R'), (1.41, 1.55, '[UNK]'), (1.55, 1.6, 'G'), (1.6, 1.63, 'L'), (1.63, 1.74, '[UNK]'), (1.74, 1.75, 'K'), (1.75, 1.76, '[UNK]'), (1.76, 1.79, 'S'), (1.79, 1.87, '[UNK]'), (1.87, 1.97, 'L'), (1.97, 2.04, '[UNK]'), (2.04, 2.14, '[SIL]')]\n",
      "\n",
      " Ground Truth \n",
      "\n",
      "[(0.0, 0.14125, 'h#'), (0.14125, 0.170625, 'd'), (0.170625, 0.2575, 'uh'), (0.2575, 0.2875, 'n'), (0.2875, 0.429, 'ae'), (0.429, 0.495, 's'), (0.495, 0.516875, 'kcl'), (0.516875, 0.54, 'k'), (0.54, 0.5535, 'm'), (0.5535, 0.595, 'ix'), (0.595, 0.6225, 'dx'), (0.6225, 0.671, 'ix'), (0.671, 0.71875, 'kcl'), (0.71875, 0.78375, 'k'), (0.78375, 0.8459375, 'eh'), (0.8459375, 0.9111875, 'r'), (0.9111875, 0.9875, 'ix'), (0.9875, 1.029625, 'n'), (1.029625, 1.201, 'oy'), (1.201, 1.2610625, 'l'), (1.2610625, 1.321125, 'ax'), (1.321125, 1.391625, 'r'), (1.391625, 1.556125, 'ae'), (1.556125, 1.588125, 'gcl'), (1.588125, 1.615, 'g'), (1.615, 1.7075, 'oy'), (1.7075, 1.8125, 'kcl'), (1.8125, 1.843125, 'dh'), (1.843125, 2.0174375, 'ae'), (2.0174375, 2.0704375, 'tcl'), (2.0704375, 2.15, 'h#')]\n"
     ]
    }
   ],
   "source": [
    "print(alignment)\n",
    "print('\\n Ground Truth \\n')\n",
    "print([(s/16000,e/16000,p) for s,e,p in zip(sample['phonetic_detail']['start'],sample['phonetic_detail']['stop'],sample['phonetic_detail']['utterance'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5R2M4YMHUf-X"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomi/Documents/tesis_speechRate/charsiu/src/Charsiu.py:372: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  audio = torch.tensor(audio).float().unsqueeze(0).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment output has been saved to sample.TextGrid\n"
     ]
    }
   ],
   "source": [
    "charsiu.serve(audio=audio_path, save_to='sample.TextGrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "yCmbdfpzXrQ3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at charsiu/en_w2v2_fc_10ms were not used when initializing Wav2Vec2ForFrameClassification: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForFrameClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForFrameClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForFrameClassification were not initialized from the model checkpoint at charsiu/en_w2v2_fc_10ms and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "None is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/None/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/hub.py:398\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1403\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, headers, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[1;32m   1402\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1405\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1261\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, headers, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1261\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1262\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;66;03m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1674\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1674\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1676\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1682\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1683\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:369\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 369\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:393\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    392\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 393\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:352\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    344\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    351\u001b[0m     )\n\u001b[0;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-6659f92a-00e1a4f405305ae0557fba89;1d037f02-479e-417c-b9af-11eba3448e12)\n\nRepository Not Found for url: https://huggingface.co/None/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m charsiu \u001b[38;5;241m=\u001b[39m \u001b[43mcharsiu_chain_forced_aligner\u001b[49m\u001b[43m(\u001b[49m\u001b[43maligner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcharsiu/en_w2v2_fc_10ms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tesis_speechRate/charsiu/src/Charsiu.py:433\u001b[0m, in \u001b[0;36mcharsiu_chain_forced_aligner.__init__\u001b[0;34m(self, aligner, recognizer, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28msuper\u001b[39m(charsiu_chain_forced_aligner, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maligner \u001b[38;5;241m=\u001b[39m Wav2Vec2ForFrameClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(aligner)\n\u001b[0;32m--> 433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognizer \u001b[38;5;241m=\u001b[39m \u001b[43mWav2Vec2ForCTC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecognizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_freeze_model()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:2899\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2896\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   2898\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[0;32m-> 2899\u001b[0m         resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2900\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2901\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2902\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2903\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2904\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2905\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2906\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2907\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2908\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2909\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2910\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2911\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2912\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2913\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2914\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m   2915\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/hub.py:421\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    422\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    425\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    426\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: None is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "charsiu = charsiu_chain_forced_aligner(aligner='charsiu/en_w2v2_fc_10ms',recognizer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "SdZqWsE45Swv"
   },
   "outputs": [],
   "source": [
    "alignment = charsiu.align(audio=audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68sFGMxN5Y7b",
    "outputId": "493ed56f-64fb-43a4-ed64-e5257896a2b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 0.1, '[SIL]'), (0.1, 0.13, '[UNK]'), (0.13, 0.17, 'S'), (0.17, 0.19, '[UNK]'), (0.19, 0.22, 'L'), (0.22, 0.25, '[UNK]'), (0.25, 0.3, 'D'), (0.3, 0.32, 'T'), (0.32, 0.43, '[UNK]'), (0.43, 0.48, 'S'), (0.48, 0.53, 'K'), (0.53, 0.55, 'M'), (0.55, 0.59, '[UNK]'), (0.59, 0.61, 'Y'), (0.61, 0.63, 'T'), (0.63, 0.64, '[UNK]'), (0.64, 0.68, 'W'), (0.68, 0.74, 'K'), (0.74, 0.75, '[UNK]'), (0.75, 0.76, 'K'), (0.76, 0.87, '[UNK]'), (0.87, 0.9, 'R'), (0.9, 0.94, '[UNK]'), (0.94, 0.95, 'Y'), (0.95, 0.99, '[UNK]'), (0.99, 1.04, 'N'), (1.04, 1.06, '[UNK]'), (1.06, 1.14, 'Y'), (1.14, 1.18, 'W'), (1.18, 1.24, '[UNK]'), (1.24, 1.32, 'L'), (1.32, 1.41, 'R'), (1.41, 1.55, '[UNK]'), (1.55, 1.6, 'G'), (1.6, 1.61, 'D'), (1.61, 1.62, 'L'), (1.62, 1.76, '[UNK]'), (1.76, 1.78, 'S'), (1.78, 1.8, 'D'), (1.8, 1.87, '[UNK]'), (1.87, 1.97, 'L'), (1.97, 2.04, '[UNK]'), (2.04, 2.14, '[SIL]')]\n",
      "\n",
      " Ground Truth \n",
      "\n",
      "[(0.0, 0.14125, 'h#'), (0.14125, 0.170625, 'd'), (0.170625, 0.2575, 'uh'), (0.2575, 0.2875, 'n'), (0.2875, 0.429, 'ae'), (0.429, 0.495, 's'), (0.495, 0.516875, 'kcl'), (0.516875, 0.54, 'k'), (0.54, 0.5535, 'm'), (0.5535, 0.595, 'ix'), (0.595, 0.6225, 'dx'), (0.6225, 0.671, 'ix'), (0.671, 0.71875, 'kcl'), (0.71875, 0.78375, 'k'), (0.78375, 0.8459375, 'eh'), (0.8459375, 0.9111875, 'r'), (0.9111875, 0.9875, 'ix'), (0.9875, 1.029625, 'n'), (1.029625, 1.201, 'oy'), (1.201, 1.2610625, 'l'), (1.2610625, 1.321125, 'ax'), (1.321125, 1.391625, 'r'), (1.391625, 1.556125, 'ae'), (1.556125, 1.588125, 'gcl'), (1.588125, 1.615, 'g'), (1.615, 1.7075, 'oy'), (1.7075, 1.8125, 'kcl'), (1.8125, 1.843125, 'dh'), (1.843125, 2.0174375, 'ae'), (2.0174375, 2.0704375, 'tcl'), (2.0704375, 2.15, 'h#')]\n"
     ]
    }
   ],
   "source": [
    "print(alignment)\n",
    "print('\\n Ground Truth \\n')\n",
    "print([(s/16000,e/16000,p) for s,e,p in zip(sample['phonetic_detail']['start'],sample['phonetic_detail']['stop'],sample['phonetic_detail']['utterance'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PqI70asA5btU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment output has been saved to sample.TextGrid\n"
     ]
    }
   ],
   "source": [
    "charsiu.serve(audio=audio_path, save_to='sample.TextGrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2hj-1ZJ1tfA"
   },
   "source": [
    "Direct inference with frame classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yG_eg8KJ1snD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at charsiu/en_w2v2_fc_10ms were not used when initializing Wav2Vec2ForFrameClassification: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForFrameClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForFrameClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForFrameClassification were not initialized from the model checkpoint at charsiu/en_w2v2_fc_10ms and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "charsiu = charsiu_predictive_aligner(aligner='charsiu/en_w2v2_fc_10ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qmkfJ9gD1tE0"
   },
   "outputs": [],
   "source": [
    "alignment = charsiu.align(audio=audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRQr20Av2Iq7",
    "outputId": "7b1802ac-0ea9-4582-ec92-b1e9282122c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 0.1, '[SIL]'), (0.1, 0.19, 'D'), (0.19, 0.2, 'OW'), (0.2, 0.24, 'AH'), (0.24, 0.29, 'N'), (0.29, 0.43, 'AE'), (0.43, 0.48, 'S'), (0.48, 0.52, 'K'), (0.52, 0.55, 'M'), (0.55, 0.59, 'IY'), (0.59, 0.63, 'T'), (0.63, 0.67, 'AH'), (0.67, 0.77, 'K'), (0.77, 0.86, 'EH'), (0.86, 0.91, 'R'), (0.91, 0.94, 'IY'), (0.94, 0.97, 'AH'), (0.97, 1.03, 'N'), (1.03, 1.16, 'OY'), (1.16, 1.18, 'IH'), (1.18, 1.26, 'L'), (1.26, 1.33, 'AH'), (1.33, 1.39, 'R'), (1.39, 1.54, 'AE'), (1.54, 1.58, 'G'), (1.58, 1.62, 'L'), (1.62, 1.69, 'AY'), (1.69, 1.77, 'K'), (1.77, 1.84, 'DH'), (1.84, 2.01, 'AE'), (2.01, 2.04, 'T'), (2.04, 2.14, '[SIL]')]\n",
      "\n",
      " Ground Truth \n",
      "\n",
      "[(0.0, 0.14125, 'h#'), (0.14125, 0.170625, 'd'), (0.170625, 0.2575, 'uh'), (0.2575, 0.2875, 'n'), (0.2875, 0.429, 'ae'), (0.429, 0.495, 's'), (0.495, 0.516875, 'kcl'), (0.516875, 0.54, 'k'), (0.54, 0.5535, 'm'), (0.5535, 0.595, 'ix'), (0.595, 0.6225, 'dx'), (0.6225, 0.671, 'ix'), (0.671, 0.71875, 'kcl'), (0.71875, 0.78375, 'k'), (0.78375, 0.8459375, 'eh'), (0.8459375, 0.9111875, 'r'), (0.9111875, 0.9875, 'ix'), (0.9875, 1.029625, 'n'), (1.029625, 1.201, 'oy'), (1.201, 1.2610625, 'l'), (1.2610625, 1.321125, 'ax'), (1.321125, 1.391625, 'r'), (1.391625, 1.556125, 'ae'), (1.556125, 1.588125, 'gcl'), (1.588125, 1.615, 'g'), (1.615, 1.7075, 'oy'), (1.7075, 1.8125, 'kcl'), (1.8125, 1.843125, 'dh'), (1.843125, 2.0174375, 'ae'), (2.0174375, 2.0704375, 'tcl'), (2.0704375, 2.15, 'h#')]\n"
     ]
    }
   ],
   "source": [
    "print(alignment)\n",
    "print('\\n Ground Truth \\n')\n",
    "print([(s/16000,e/16000,p) for s,e,p in zip(sample['phonetic_detail']['start'],sample['phonetic_detail']['stop'],sample['phonetic_detail']['utterance'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwTpN_5c2Zm1",
    "outputId": "ac8b79e3-9c5c-439f-be60-2773c730e19f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment output has been saved to sample.TextGrid\n"
     ]
    }
   ],
   "source": [
    "charsiu.serve(audio=audio_path, save_to='sample.TextGrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rompo Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def align(self, audio):\n",
    "        '''\n",
    "        Recognize phones and perform forced alignment\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        audio : np.ndarray [shape=(n,)]\n",
    "            time series of speech signal\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A tuple of aligned phones in the form (start_time, end_time, phone)\n",
    "\n",
    "        '''\n",
    "        if self.recognizer is None:\n",
    "            print('A recognizer is not specified. Will use the default recognizer.')\n",
    "            self.recognizer = Wav2Vec2ForCTC.from_pretrained('charsiu/en_w2v2_ctc_libris_and_cv')\n",
    "        \n",
    "        # perform phone recognition\n",
    "        audio = self.charsiu_processor.audio_preprocess(audio,sr=self.sr)\n",
    "        audio = torch.tensor(audio).float().unsqueeze(0).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out = self.recognizer(audio)\n",
    "            \n",
    "        pred_ids = torch.argmax(out.logits,dim=-1).squeeze()\n",
    "        phones = self.charsiu_processor.processor.tokenizer.convert_ids_to_tokens(pred_ids,skip_special_tokens=True)\n",
    "        phones = [p for p,group in groupby(phones)]\n",
    "        phone_ids = self.charsiu_processor.get_phone_ids(phones)\n",
    "        \n",
    "        # perform forced alignment\n",
    "        batch = {'input_values':audio,\n",
    "         'labels': torch.tensor(phone_ids).unsqueeze(0).long().to(self.device)\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "          out = self.aligner(**batch)\n",
    "        att = torch.softmax(out.logits,dim=-1)\n",
    "        \n",
    "        preds = torch.argmax(att[0],dim=-1).cpu().detach().squeeze().numpy()\n",
    "        pred_phones = [self.charsiu_processor.mapping_id2phone(phone_ids[i]) for i in preds]\n",
    "        pred_phones = seq2duration(pred_phones,resolution=self.resolution)\n",
    "        return pred_phones\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at charsiu/en_w2v2_fs_10ms were not used when initializing Wav2Vec2ForAttentionAlignment: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForAttentionAlignment from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForAttentionAlignment from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForAttentionAlignment were not initialized from the model checkpoint at charsiu/en_w2v2_fs_10ms and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at charsiu/en_w2v2_ctc_libris_and_cv were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at charsiu/en_w2v2_ctc_libris_and_cv and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "charsiu_at_al = charsiu_chain_attention_aligner(aligner='charsiu/en_w2v2_fs_10ms',recognizer='charsiu/en_w2v2_ctc_libris_and_cv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text transcription:Don't ask me to carry an oily rag like that.\n",
      "Audio path: /home/tomi/Documents/tesis_speechRate/timit/data/TRAIN/DR1/FCJF0/SA2.WAV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomi/Documents/tesis_speechRate/charsiu/src/Charsiu.py:372: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  audio = torch.tensor(audio).float().unsqueeze(0).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 0.1, '[SIL]'), (0.1, 0.12, '[UNK]'), (0.12, 0.17, 'S'), (0.17, 0.19, '[UNK]'), (0.19, 0.2, 'L'), (0.2, 0.26, '[UNK]'), (0.26, 0.3, 'D'), (0.3, 0.32, 'T'), (0.32, 0.43, '[UNK]'), (0.43, 0.48, 'S'), (0.48, 0.51, 'K'), (0.51, 0.55, 'M'), (0.55, 0.58, '[UNK]'), (0.58, 0.6, 'Y'), (0.6, 0.64, 'T'), (0.64, 0.68, 'W'), (0.68, 0.73, 'K'), (0.73, 0.74, '[UNK]'), (0.74, 0.76, 'K'), (0.76, 0.87, '[UNK]'), (0.87, 0.9, 'R'), (0.9, 0.94, '[UNK]'), (0.94, 0.95, 'Y'), (0.95, 0.98, '[UNK]'), (0.98, 1.02, 'N'), (1.02, 1.05, '[UNK]'), (1.05, 1.15, 'Y'), (1.15, 1.18, 'W'), (1.18, 1.19, '[UNK]'), (1.19, 1.2, 'W'), (1.2, 1.23, '[UNK]'), (1.23, 1.33, 'L'), (1.33, 1.41, 'R'), (1.41, 1.56, '[UNK]'), (1.56, 1.6, 'G'), (1.6, 1.62, 'L'), (1.62, 1.76, '[UNK]'), (1.76, 1.78, 'D'), (1.78, 1.79, 'S'), (1.79, 1.8, 'D'), (1.8, 1.88, '[UNK]'), (1.88, 1.97, 'L'), (1.97, 2.04, '[UNK]'), (2.04, 2.14, '[SIL]')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22846/3609181609.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  audio = torch.tensor(audio).float().unsqueeze(0).to(charsiu_at_al.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[SIL]', '[SIL]', '[SIL]', '[SIL]', '[SIL]', '[SIL]', '[SIL]', '[SIL]', '[SIL]', '[SIL]', '[UNK]', '[UNK]', 'S', 'S', 'S', 'S', 'S', '[UNK]', '[UNK]', 'L', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'D', 'D', 'D', 'D', 'T', 'T', 'T', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'S', 'S', 'S', 'S', 'S', 'K', 'K', 'K', 'M', 'M', 'M', 'M', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'Y', 'Y', 'T', 'T', '[UNK]', 'W', 'W', 'W', 'W', 'K', 'K', 'K', 'K', 'K', '[UNK]', '[UNK]', 'K', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'R', 'R', 'R', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'Y', '[UNK]', '[UNK]', '[UNK]', 'N', 'N', 'N', 'N', 'N', '[UNK]', '[UNK]', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'W', 'W', 'W', 'W', 'W', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'G', 'G', 'G', 'G', 'L', 'L', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'K', 'K', '[UNK]', 'S', 'S', 'S', 'S', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[SIL]', '[SIL]', '[SIL]', '[SIL]', '[SIL]', '[SIL]', '[SIL]', '[SIL]', '[SIL]', '[SIL]']\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "sample = timit['train'][1]\n",
    "text = sample['text']\n",
    "audio_path = sample['file']\n",
    "print('Text transcription:%s'%(text))\n",
    "print('Audio path: %s'%audio_path)\n",
    "audio = sample['audio']['array']\n",
    "\n",
    "aligner = charsiu_at_al.align(audio_path)\n",
    "print(aligner)\n",
    "\n",
    "\n",
    "# perform phone recognition\n",
    "audio = charsiu_at_al.charsiu_processor.audio_preprocess(audio,sr=charsiu_at_al.sr)\n",
    "audio = torch.tensor(audio).float().unsqueeze(0).to(charsiu_at_al.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = charsiu_at_al.recognizer(audio)\n",
    "\n",
    "pred_ids = torch.argmax(out.logits,dim=-1).squeeze()\n",
    "phones = charsiu_at_al.charsiu_processor.processor.tokenizer.convert_ids_to_tokens(pred_ids,skip_special_tokens=True)\n",
    "phones = [p for p,group in groupby(phones)]\n",
    "phone_ids = charsiu_at_al.charsiu_processor.get_phone_ids(phones) # TODO: el error puede estar aca\n",
    "\n",
    "# perform forced alignment\n",
    "batch = {'input_values':audio,\n",
    " 'labels': torch.tensor(phone_ids).unsqueeze(0).long().to(charsiu_at_al.device)\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "  out = charsiu_at_al.aligner(**batch)\n",
    "att = torch.softmax(out.logits,dim=-1)\n",
    "\n",
    "preds = torch.argmax(att[0],dim=-1).cpu().detach().squeeze().numpy()\n",
    "pred_phones = [charsiu_at_al.charsiu_processor.mapping_id2phone(phone_ids[i]) for i in preds]\n",
    "#pred_phones = seq2duration(pred_phones,resolution=charsiu_at_al.resolution)\n",
    "print( pred_phones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phone_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby, chain\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phones = list(chain.from_iterable(phones))\n",
    "ids = [charsiu_at_al.charsiu_processor.mapping_phone2id(re.sub(r'\\d','',p)) for p in phones]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 36,\n",
       " 12,\n",
       " 7,\n",
       " 22,\n",
       " 4,\n",
       " 38,\n",
       " 17,\n",
       " 3,\n",
       " 8,\n",
       " 22,\n",
       " 6,\n",
       " 17,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 39,\n",
       " 7,\n",
       " 34,\n",
       " 19,\n",
       " 25,\n",
       " 32,\n",
       " 5,\n",
       " 4,\n",
       " 31,\n",
       " 32,\n",
       " 37,\n",
       " 17,\n",
       " 29,\n",
       " 4,\n",
       " 22,\n",
       " 0]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 40, 40, 36, 40, 22, 0]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charsiu_at_al.charsiu_processor.get_phone_ids(['AE', 'DH', 'T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'S',\n",
       " 'I',\n",
       " 'L',\n",
       " ']',\n",
       " 'D',\n",
       " 'O',\n",
       " 'W',\n",
       " 'N',\n",
       " 'T',\n",
       " 'A',\n",
       " 'E',\n",
       " 'S',\n",
       " 'K',\n",
       " 'M',\n",
       " 'I',\n",
       " 'Y',\n",
       " 'T',\n",
       " 'U',\n",
       " 'W',\n",
       " 'K',\n",
       " 'A',\n",
       " 'E',\n",
       " 'R',\n",
       " 'I',\n",
       " 'Y',\n",
       " 'I',\n",
       " 'H',\n",
       " 'N',\n",
       " 'O',\n",
       " 'Y',\n",
       " 'W',\n",
       " 'A',\n",
       " 'H',\n",
       " 'L',\n",
       " 'R',\n",
       " 'A',\n",
       " 'E',\n",
       " 'G',\n",
       " 'L',\n",
       " 'A',\n",
       " 'Y',\n",
       " 'K',\n",
       " 'D',\n",
       " 'H',\n",
       " 'A',\n",
       " 'E',\n",
       " 'T',\n",
       " '[',\n",
       " 'S',\n",
       " 'I',\n",
       " 'L',\n",
       " ']']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[SIL]', 'D', 'T', '[SIL]']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charsiu_at_al.charsiu_processor.processor.tokenizer.convert_ids_to_tokens([0, 40, 40, 36, 40, 22, 0],skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[SIL]', '[UNK]', '[UNK]', 'D', '[UNK]', 'T', '[SIL]']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = [0, 40, 40, 36, 40, 22, 0]\n",
    "[charsiu_at_al.charsiu_processor.mapping_id2phone(i) for i in lista]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyQuadMesh at 0x7295964adc00>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.pcolor(att[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2867358495.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[93], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    charsiu_at_al.charsiu_processor.\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "charsiu_at_al.charsiu_processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample['phonetic_detail']['utterance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22846/2673428831.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  audio = torch.tensor(audio).float().unsqueeze(0).to(charsiu.device)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "charsiu_demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
