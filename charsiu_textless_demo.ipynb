{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "0zxKOeyTROc2"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'autoreload' was not found in history, as a file, url, nor in the user namespace.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3877\u001b[0m, in \u001b[0;36mInteractiveShell.find_user_code\u001b[0;34m(self, target, raw, py_only, skip_encoding_cookie, search_ns)\u001b[0m\n\u001b[1;32m   3876\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:                                              \u001b[38;5;66;03m# User namespace\u001b[39;00m\n\u001b[0;32m-> 3877\u001b[0m     codeobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3878\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'autoreload' is not defined",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mload\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mautoreload\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2456\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2454\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2455\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2456\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2458\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2459\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2460\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/magics/code.py:359\u001b[0m, in \u001b[0;36mCodeMagics.load\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m    357\u001b[0m opts,args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_options(arg_s,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myns:r:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    358\u001b[0m search_ns \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m opts\n\u001b[0;32m--> 359\u001b[0m contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_user_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_ns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m opts:\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3879\u001b[0m, in \u001b[0;36mInteractiveShell.find_user_code\u001b[0;34m(self, target, raw, py_only, skip_encoding_cookie, search_ns)\u001b[0m\n\u001b[1;32m   3877\u001b[0m     codeobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns)\n\u001b[1;32m   3878\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3879\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m was not found in history, as a file, url, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3880\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnor in the user namespace.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m%\u001b[39m target) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   3882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(codeobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   3883\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codeobj\n",
      "\u001b[0;31mValueError\u001b[0m: 'autoreload' was not found in history, as a file, url, nor in the user namespace."
     ]
    }
   ],
   "source": [
    "%load autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DIROcsj7Rv4g",
    "outputId": "290c10ae-5ee4-4b9f-86de-8de075c80a76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%auoreload` not found.\n"
     ]
    }
   ],
   "source": [
    "%auoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GmHNb4OxRVD8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomi/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "from itertools import groupby\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from charsiu.src.Charsiu import Wav2Vec2ForFrameClassification, CharsiuPreprocessor_en, charsiu_forced_aligner, charsiu_chain_attention_aligner, charsiu_chain_forced_aligner, charsiu_predictive_aligner\n",
    "from charsiu.src.utils import seq2duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "q7paWfYdROc5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomi/.local/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for timit_asr contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/timit_asr\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# download timit\n",
    "timit = load_dataset('timit_asr', data_dir='/home/tomi/Documents/tesis_speechRate/timit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "psXcfdsd48NJ",
    "outputId": "8b13c545-1e59-4e4e-cb4e-d3b021a88e3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text transcription:Don't ask me to carry an oily rag like that.\n",
      "Audio path: /home/tomi/Documents/tesis_speechRate/timit/data/TRAIN/DR1/FCJF0/SA2.WAV\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "sample = timit['train'][1]\n",
    "text = sample['text']\n",
    "audio_path = sample['file']\n",
    "print('Text transcription:%s'%(text))\n",
    "print('Audio path: %s'%audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUye9Hgpzpxb"
   },
   "source": [
    "Phone recognizer + Neural Forced Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yHW92QgDROc4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomi/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "/home/tomi/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of the model checkpoint at charsiu/en_w2v2_fs_10ms were not used when initializing Wav2Vec2ForAttentionAlignment: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForAttentionAlignment from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForAttentionAlignment from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForAttentionAlignment were not initialized from the model checkpoint at charsiu/en_w2v2_fs_10ms and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at charsiu/en_w2v2_ctc_libris_and_cv were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at charsiu/en_w2v2_ctc_libris_and_cv and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Wav2Vec2ForCTC(\n",
       "  (wav2vec2): Wav2Vec2Model(\n",
       "    (feature_extractor): Wav2Vec2FeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Wav2Vec2GroupNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): Wav2Vec2FeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): Wav2Vec2Encoder(\n",
       "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "        (conv): ParametrizedConv1d(\n",
       "          768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (padding): Wav2Vec2SamePadLayer()\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (lm_head): Linear(in_features=768, out_features=42, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "charsiu = charsiu_chain_attention_aligner(aligner='charsiu/en_w2v2_fs_10ms',recognizer='charsiu/en_w2v2_ctc_libris_and_cv')\n",
    "charsiu.recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gJkF2z91ROc5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomi/Documents/tesis_speechRate/charsiu/src/Charsiu.py:372: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  audio = torch.tensor(audio).float().unsqueeze(0).to(self.device)\n"
     ]
    }
   ],
   "source": [
    "alignment = charsiu.align(audio=audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Wav2Vec2ForCTC.forward() missing 1 required positional argument: 'input_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcharsiu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Wav2Vec2ForCTC.forward() missing 1 required positional argument: 'input_values'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "charsiu.recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gLE1r9LQ5CYq",
    "outputId": "cdd35c8f-620b-4d04-d51e-bf37d9ebcf21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 0.1, '[UNK]'), (0.1, 0.16, 'S'), (0.16, 0.19, '[UNK]'), (0.19, 0.21, 'L'), (0.21, 0.26, '[UNK]'), (0.26, 0.29, 'D'), (0.29, 0.31, 'T'), (0.31, 0.43, '[UNK]'), (0.43, 0.48, 'S'), (0.48, 0.52, 'K'), (0.52, 0.55, 'M'), (0.55, 0.59, '[UNK]'), (0.59, 0.6, 'Y'), (0.6, 0.63, 'T'), (0.63, 0.64, '[UNK]'), (0.64, 0.67, 'W'), (0.67, 0.75, 'K'), (0.75, 0.87, '[UNK]'), (0.87, 0.9, 'R'), (0.9, 0.93, '[UNK]'), (0.93, 0.94, 'Y'), (0.94, 0.99, '[UNK]'), (0.99, 1.02, 'N'), (1.02, 1.03, '[UNK]'), (1.03, 1.04, 'N'), (1.04, 1.05, '[UNK]'), (1.05, 1.1, 'Y'), (1.1, 1.11, 'W'), (1.11, 1.13, 'Y'), (1.13, 1.17, 'W'), (1.17, 1.18, '[UNK]'), (1.18, 1.19, 'W'), (1.19, 1.25, '[UNK]'), (1.25, 1.33, 'L'), (1.33, 1.41, 'R'), (1.41, 1.56, '[UNK]'), (1.56, 1.6, 'G'), (1.6, 1.63, 'L'), (1.63, 1.65, '[UNK]'), (1.65, 1.66, 'Y'), (1.66, 1.7, '[UNK]'), (1.7, 1.72, 'K'), (1.72, 1.77, '[UNK]'), (1.77, 1.79, 'S'), (1.79, 1.8, 'D'), (1.8, 1.82, 'S'), (1.82, 1.96, '[UNK]'), (1.96, 2.04, 'L'), (2.04, 2.14, '[UNK]')]\n",
      "\n",
      " Ground Truth \n",
      "\n",
      "[(0.0, 0.14125, 'h#'), (0.14125, 0.170625, 'd'), (0.170625, 0.2575, 'uh'), (0.2575, 0.2875, 'n'), (0.2875, 0.429, 'ae'), (0.429, 0.495, 's'), (0.495, 0.516875, 'kcl'), (0.516875, 0.54, 'k'), (0.54, 0.5535, 'm'), (0.5535, 0.595, 'ix'), (0.595, 0.6225, 'dx'), (0.6225, 0.671, 'ix'), (0.671, 0.71875, 'kcl'), (0.71875, 0.78375, 'k'), (0.78375, 0.8459375, 'eh'), (0.8459375, 0.9111875, 'r'), (0.9111875, 0.9875, 'ix'), (0.9875, 1.029625, 'n'), (1.029625, 1.201, 'oy'), (1.201, 1.2610625, 'l'), (1.2610625, 1.321125, 'ax'), (1.321125, 1.391625, 'r'), (1.391625, 1.556125, 'ae'), (1.556125, 1.588125, 'gcl'), (1.588125, 1.615, 'g'), (1.615, 1.7075, 'oy'), (1.7075, 1.8125, 'kcl'), (1.8125, 1.843125, 'dh'), (1.843125, 2.0174375, 'ae'), (2.0174375, 2.0704375, 'tcl'), (2.0704375, 2.15, 'h#')]\n"
     ]
    }
   ],
   "source": [
    "print(alignment)\n",
    "print('\\n Ground Truth \\n')\n",
    "print([(s/16000,e/16000,p) for s,e,p in zip(sample['phonetic_detail']['start'],sample['phonetic_detail']['stop'],sample['phonetic_detail']['utterance'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5R2M4YMHUf-X"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomi/Documents/tesis_speechRate/charsiu/src/Charsiu.py:372: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  audio = torch.tensor(audio).float().unsqueeze(0).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment output has been saved to sample.TextGrid\n"
     ]
    }
   ],
   "source": [
    "charsiu.serve(audio=audio_path, save_to='sample.TextGrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yCmbdfpzXrQ3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomi/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at charsiu/en_w2v2_fc_10ms were not used when initializing Wav2Vec2ForFrameClassification: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForFrameClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForFrameClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForFrameClassification were not initialized from the model checkpoint at charsiu/en_w2v2_fc_10ms and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "None is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/None/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/hub.py:398\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1403\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, headers, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[1;32m   1402\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1405\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1261\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, headers, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1261\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1262\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;66;03m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1674\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1674\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1676\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1682\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1683\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:369\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 369\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:393\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    392\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 393\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:352\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    344\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    351\u001b[0m     )\n\u001b[0;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-665b273a-47aae96c0f0b70293ab24208;8f252a6c-9d62-4ad3-aeba-a1fc91990421)\n\nRepository Not Found for url: https://huggingface.co/None/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m charsiu \u001b[38;5;241m=\u001b[39m \u001b[43mcharsiu_chain_forced_aligner\u001b[49m\u001b[43m(\u001b[49m\u001b[43maligner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcharsiu/en_w2v2_fc_10ms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tesis_speechRate/charsiu/src/Charsiu.py:433\u001b[0m, in \u001b[0;36mcharsiu_chain_forced_aligner.__init__\u001b[0;34m(self, aligner, recognizer, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28msuper\u001b[39m(charsiu_chain_forced_aligner, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maligner \u001b[38;5;241m=\u001b[39m Wav2Vec2ForFrameClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(aligner)\n\u001b[0;32m--> 433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognizer \u001b[38;5;241m=\u001b[39m \u001b[43mWav2Vec2ForCTC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecognizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_freeze_model()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:2899\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2896\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   2898\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[0;32m-> 2899\u001b[0m         resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2900\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2901\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2902\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2903\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2904\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2905\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2906\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2907\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2908\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2909\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2910\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2911\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2912\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2913\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2914\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m   2915\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/hub.py:421\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    422\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    425\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    426\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: None is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "charsiu = charsiu_chain_forced_aligner(aligner='charsiu/en_w2v2_fc_10ms',recognizer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SdZqWsE45Swv"
   },
   "outputs": [],
   "source": [
    "alignment = charsiu.align(audio=audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68sFGMxN5Y7b",
    "outputId": "493ed56f-64fb-43a4-ed64-e5257896a2b0"
   },
   "outputs": [],
   "source": [
    "print(alignment)\n",
    "print('\\n Ground Truth \\n')\n",
    "print([(s/16000,e/16000,p) for s,e,p in zip(sample['phonetic_detail']['start'],sample['phonetic_detail']['stop'],sample['phonetic_detail']['utterance'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PqI70asA5btU"
   },
   "outputs": [],
   "source": [
    "charsiu.serve(audio=audio_path, save_to='sample.TextGrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2hj-1ZJ1tfA"
   },
   "source": [
    "Direct inference with frame classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yG_eg8KJ1snD"
   },
   "outputs": [],
   "source": [
    "charsiu = charsiu_predictive_aligner(aligner='charsiu/en_w2v2_fc_10ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qmkfJ9gD1tE0"
   },
   "outputs": [],
   "source": [
    "alignment = charsiu.align(audio=audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRQr20Av2Iq7",
    "outputId": "7b1802ac-0ea9-4582-ec92-b1e9282122c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 0.1, '[UNK]'), (0.1, 0.16, 'S'), (0.16, 0.19, '[UNK]'), (0.19, 0.21, 'L'), (0.21, 0.26, '[UNK]'), (0.26, 0.29, 'D'), (0.29, 0.31, 'T'), (0.31, 0.43, '[UNK]'), (0.43, 0.48, 'S'), (0.48, 0.52, 'K'), (0.52, 0.55, 'M'), (0.55, 0.59, '[UNK]'), (0.59, 0.6, 'Y'), (0.6, 0.63, 'T'), (0.63, 0.64, '[UNK]'), (0.64, 0.67, 'W'), (0.67, 0.75, 'K'), (0.75, 0.87, '[UNK]'), (0.87, 0.9, 'R'), (0.9, 0.93, '[UNK]'), (0.93, 0.94, 'Y'), (0.94, 0.99, '[UNK]'), (0.99, 1.02, 'N'), (1.02, 1.03, '[UNK]'), (1.03, 1.04, 'N'), (1.04, 1.05, '[UNK]'), (1.05, 1.1, 'Y'), (1.1, 1.11, 'W'), (1.11, 1.13, 'Y'), (1.13, 1.17, 'W'), (1.17, 1.18, '[UNK]'), (1.18, 1.19, 'W'), (1.19, 1.25, '[UNK]'), (1.25, 1.33, 'L'), (1.33, 1.41, 'R'), (1.41, 1.56, '[UNK]'), (1.56, 1.6, 'G'), (1.6, 1.63, 'L'), (1.63, 1.65, '[UNK]'), (1.65, 1.66, 'Y'), (1.66, 1.7, '[UNK]'), (1.7, 1.72, 'K'), (1.72, 1.77, '[UNK]'), (1.77, 1.79, 'S'), (1.79, 1.8, 'D'), (1.8, 1.82, 'S'), (1.82, 1.96, '[UNK]'), (1.96, 2.04, 'L'), (2.04, 2.14, '[UNK]')]\n",
      "\n",
      " Ground Truth \n",
      "\n",
      "[(0.0, 0.14125, 'h#'), (0.14125, 0.170625, 'd'), (0.170625, 0.2575, 'uh'), (0.2575, 0.2875, 'n'), (0.2875, 0.429, 'ae'), (0.429, 0.495, 's'), (0.495, 0.516875, 'kcl'), (0.516875, 0.54, 'k'), (0.54, 0.5535, 'm'), (0.5535, 0.595, 'ix'), (0.595, 0.6225, 'dx'), (0.6225, 0.671, 'ix'), (0.671, 0.71875, 'kcl'), (0.71875, 0.78375, 'k'), (0.78375, 0.8459375, 'eh'), (0.8459375, 0.9111875, 'r'), (0.9111875, 0.9875, 'ix'), (0.9875, 1.029625, 'n'), (1.029625, 1.201, 'oy'), (1.201, 1.2610625, 'l'), (1.2610625, 1.321125, 'ax'), (1.321125, 1.391625, 'r'), (1.391625, 1.556125, 'ae'), (1.556125, 1.588125, 'gcl'), (1.588125, 1.615, 'g'), (1.615, 1.7075, 'oy'), (1.7075, 1.8125, 'kcl'), (1.8125, 1.843125, 'dh'), (1.843125, 2.0174375, 'ae'), (2.0174375, 2.0704375, 'tcl'), (2.0704375, 2.15, 'h#')]\n"
     ]
    }
   ],
   "source": [
    "print(alignment)\n",
    "print('\\n Ground Truth \\n')\n",
    "print([(s/16000,e/16000,p) for s,e,p in zip(sample['phonetic_detail']['start'],sample['phonetic_detail']['stop'],sample['phonetic_detail']['utterance'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwTpN_5c2Zm1",
    "outputId": "ac8b79e3-9c5c-439f-be60-2773c730e19f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment output has been saved to sample.TextGrid\n"
     ]
    }
   ],
   "source": [
    "charsiu.serve(audio=audio_path, save_to='sample.TextGrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rompo Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def align(self, audio):\n",
    "        '''\n",
    "        Recognize phones and perform forced alignment\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        audio : np.ndarray [shape=(n,)]\n",
    "            time series of speech signal\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A tuple of aligned phones in the form (start_time, end_time, phone)\n",
    "\n",
    "        '''\n",
    "        if self.recognizer is None:\n",
    "            print('A recognizer is not specified. Will use the default recognizer.')\n",
    "            self.recognizer = Wav2Vec2ForCTC.from_pretrained('charsiu/en_w2v2_ctc_libris_and_cv')\n",
    "        \n",
    "        # perform phone recognition\n",
    "        audio = self.charsiu_processor.audio_preprocess(audio,sr=self.sr)\n",
    "        audio = torch.tensor(audio).float().unsqueeze(0).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out = self.recognizer(audio)\n",
    "            \n",
    "        pred_ids = torch.argmax(out.logits,dim=-1).squeeze()\n",
    "        phones = self.charsiu_processor.processor.tokenizer.convert_ids_to_tokens(pred_ids,skip_special_tokens=True)\n",
    "        phones = [p for p,group in groupby(phones)]\n",
    "        phone_ids = self.charsiu_processor.get_phone_ids(phones)\n",
    "        \n",
    "        # perform forced alignment\n",
    "        batch = {'input_values':audio,\n",
    "         'labels': torch.tensor(phone_ids).unsqueeze(0).long().to(self.device)\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "          out = self.aligner(**batch)\n",
    "        att = torch.softmax(out.logits,dim=-1)\n",
    "        \n",
    "        preds = torch.argmax(att[0],dim=-1).cpu().detach().squeeze().numpy()\n",
    "        pred_phones = [self.charsiu_processor.mapping_id2phone(phone_ids[i]) for i in preds]\n",
    "        pred_phones = seq2duration(pred_phones,resolution=self.resolution)\n",
    "        return pred_phones\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at charsiu/en_w2v2_fs_10ms were not used when initializing Wav2Vec2ForAttentionAlignment: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForAttentionAlignment from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForAttentionAlignment from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForAttentionAlignment were not initialized from the model checkpoint at charsiu/en_w2v2_fs_10ms and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at charsiu/en_w2v2_ctc_libris_and_cv were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at charsiu/en_w2v2_ctc_libris_and_cv and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "charsiu_at_al = charsiu_chain_attention_aligner(aligner='charsiu/en_w2v2_fs_10ms',recognizer='charsiu/en_w2v2_ctc_libris_and_cv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text transcription:Don't ask me to carry an oily rag like that.\n",
      "Audio path: /home/tomi/Documents/tesis_speechRate/timit/data/TRAIN/DR1/FCJF0/SA2.WAV\n",
      "[(0.0, 0.1, '[UNK]'), (0.1, 0.16, 'S'), (0.16, 0.19, '[UNK]'), (0.19, 0.21, 'L'), (0.21, 0.26, '[UNK]'), (0.26, 0.29, 'D'), (0.29, 0.32, 'T'), (0.32, 0.43, '[UNK]'), (0.43, 0.48, 'S'), (0.48, 0.53, 'K'), (0.53, 0.55, 'M'), (0.55, 0.59, '[UNK]'), (0.59, 0.6, 'Y'), (0.6, 0.63, 'T'), (0.63, 0.64, '[UNK]'), (0.64, 0.68, 'W'), (0.68, 0.72, 'K'), (0.72, 0.74, '[UNK]'), (0.74, 0.76, 'K'), (0.76, 0.88, '[UNK]'), (0.88, 0.9, 'R'), (0.9, 0.94, '[UNK]'), (0.94, 0.95, 'Y'), (0.95, 0.99, '[UNK]'), (0.99, 1.02, 'N'), (1.02, 1.05, '[UNK]'), (1.05, 1.13, 'Y'), (1.13, 1.14, 'W'), (1.14, 1.15, 'Y'), (1.15, 1.18, 'W'), (1.18, 1.25, '[UNK]'), (1.25, 1.33, 'L'), (1.33, 1.4, 'R'), (1.4, 1.56, '[UNK]'), (1.56, 1.6, 'G'), (1.6, 1.62, 'L'), (1.62, 1.64, '[UNK]'), (1.64, 1.66, 'Y'), (1.66, 1.71, '[UNK]'), (1.71, 1.73, 'K'), (1.73, 1.77, '[UNK]'), (1.77, 1.78, 'S'), (1.78, 1.8, 'D'), (1.8, 1.83, 'S'), (1.83, 1.94, '[UNK]'), (1.94, 1.95, 'L'), (1.95, 1.96, '[UNK]'), (1.96, 2.04, 'L'), (2.04, 2.14, '[UNK]')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29787/3609181609.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  audio = torch.tensor(audio).float().unsqueeze(0).to(charsiu_at_al.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'S', 'S', 'S', 'S', 'S', '[UNK]', '[UNK]', '[UNK]', 'L', 'L', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'D', 'D', 'D', 'D', 'T', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'S', 'S', 'S', 'S', 'S', 'K', 'K', 'K', 'K', 'M', 'M', 'M', '[UNK]', '[UNK]', '[UNK]', 'Y', 'Y', 'T', 'T', 'T', '[UNK]', 'W', 'W', 'W', 'W', 'K', 'K', 'K', 'K', 'K', 'K', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'R', 'R', 'R', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'N', 'N', 'N', 'N', 'N', '[UNK]', '[UNK]', 'Y', 'Y', 'Y', '[UNK]', 'Y', 'Y', 'Y', 'Y', 'Y', 'W', 'W', 'W', 'W', 'W', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'G', 'G', 'G', 'G', 'L', 'L', 'L', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'K', '[UNK]', '[UNK]', '[UNK]', 'S', 'S', 'D', 'S', 'S', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]']\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "sample = timit['train'][1]\n",
    "text = sample['text']\n",
    "audio_path = sample['file']\n",
    "print('Text transcription:%s'%(text))\n",
    "print('Audio path: %s'%audio_path)\n",
    "audio = sample['audio']['array']\n",
    "\n",
    "aligner = charsiu_at_al.align(audio_path)\n",
    "print(aligner)\n",
    "\n",
    "\n",
    "# perform phone recognition\n",
    "audio = charsiu_at_al.charsiu_processor.audio_preprocess(audio,sr=charsiu_at_al.sr)\n",
    "audio = torch.tensor(audio).float().unsqueeze(0).to(charsiu_at_al.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = charsiu_at_al.recognizer(audio)\n",
    "\n",
    "pred_ids = torch.argmax(out.logits,dim=-1).squeeze()\n",
    "phones = charsiu_at_al.charsiu_processor.processor.tokenizer.convert_ids_to_tokens(pred_ids,skip_special_tokens=True)\n",
    "phones = [p for p,group in groupby(phones)]\n",
    "phone_ids = charsiu_at_al.charsiu_processor.get_phone_ids(phones) # TODO: el error puede estar aca\n",
    "\n",
    "# perform forced alignment\n",
    "batch = {'input_values':audio,\n",
    " 'labels': torch.tensor(phone_ids).unsqueeze(0).long().to(charsiu_at_al.device)\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "  out = charsiu_at_al.aligner(**batch)\n",
    "att = torch.softmax(out.logits,dim=-1)\n",
    "\n",
    "preds = torch.argmax(att[0],dim=-1).cpu().detach().squeeze().numpy()\n",
    "pred_phones = [charsiu_at_al.charsiu_processor.mapping_id2phone(phone_ids[i]) for i in preds]\n",
    "#pred_phones = seq2duration(pred_phones,resolution=charsiu_at_al.resolution)\n",
    "print( pred_phones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phone_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby, chain\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[SIL]',\n",
       " 'D',\n",
       " 'OW',\n",
       " 'N',\n",
       " 'T',\n",
       " 'AE',\n",
       " 'S',\n",
       " 'K',\n",
       " 'M',\n",
       " 'IY',\n",
       " 'T',\n",
       " 'UW',\n",
       " 'K',\n",
       " 'AE',\n",
       " 'R',\n",
       " 'IY',\n",
       " 'IH',\n",
       " 'N',\n",
       " 'OY',\n",
       " 'W',\n",
       " 'AH',\n",
       " 'L',\n",
       " 'R',\n",
       " 'AE',\n",
       " 'G',\n",
       " 'L',\n",
       " 'AY',\n",
       " 'K',\n",
       " 'DH',\n",
       " 'AE',\n",
       " 'T',\n",
       " '[SIL]']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phones = list(chain.from_iterable(phones))\n",
    "ids = [charsiu_at_al.charsiu_processor.mapping_phone2id(re.sub(r'\\d','',p)) for p in phones] # Esto anda bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 36,\n",
       " 12,\n",
       " 7,\n",
       " 22,\n",
       " 4,\n",
       " 38,\n",
       " 17,\n",
       " 3,\n",
       " 8,\n",
       " 22,\n",
       " 6,\n",
       " 17,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 39,\n",
       " 7,\n",
       " 34,\n",
       " 19,\n",
       " 25,\n",
       " 32,\n",
       " 5,\n",
       " 4,\n",
       " 31,\n",
       " 32,\n",
       " 37,\n",
       " 17,\n",
       " 29,\n",
       " 4,\n",
       " 22,\n",
       " 0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 40, 36, 40, 22]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charsiu_at_al.charsiu_processor.get_phone_ids(['AE', 'DH', 'T']) # TODO: Esto parece que es lo que anda mal  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[SIL]',\n",
       " 'D',\n",
       " 'OW',\n",
       " 'N',\n",
       " 'T',\n",
       " 'AE',\n",
       " 'S',\n",
       " 'K',\n",
       " 'M',\n",
       " 'IY',\n",
       " 'T',\n",
       " 'UW',\n",
       " 'K',\n",
       " 'AE',\n",
       " 'R',\n",
       " 'IY',\n",
       " 'IH',\n",
       " 'N',\n",
       " 'OY',\n",
       " 'W',\n",
       " 'AH',\n",
       " 'L',\n",
       " 'R',\n",
       " 'AE',\n",
       " 'G',\n",
       " 'L',\n",
       " 'AY',\n",
       " 'K',\n",
       " 'DH',\n",
       " 'AE',\n",
       " 'T',\n",
       " '[SIL]']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phones # Aparecian '[', 'S', 'I',..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[SIL]', 'D', 'T', '[SIL]']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charsiu_at_al.charsiu_processor.processor.tokenizer.convert_ids_to_tokens([0, 40, 40, 36, 40, 22, 0],skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[SIL]', '[UNK]', '[UNK]', 'D', '[UNK]', 'T', '[SIL]']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = [0, 40, 40, 36, 40, 22, 0]\n",
    "[charsiu_at_al.charsiu_processor.mapping_id2phone(i) for i in lista]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyQuadMesh at 0x729595ab5c00>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.pcolor(att[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 40, 40, 22, 0]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charsiu_at_al.charsiu_processor.get_phone_ids([ 'AE', 'T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[SIL]', 'D', 'T', '[SIL]']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charsiu_at_al.charsiu_processor.processor.tokenizer.convert_ids_to_tokens([0, 36, 22, 0],skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample['phonetic_detail']['utterance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22846/2673428831.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  audio = torch.tensor(audio).float().unsqueeze(0).to(charsiu.device)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "charsiu_demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
